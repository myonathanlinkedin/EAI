# Enterprise Approval Intelligence (EAI)

A C# .NET-based enterprise framework for transforming approvals from traditional status-based workflows to intelligent, autonomous decision-making systems powered by local LLM integration (LM Studio/qwen2.5-7b-instruct-1m) with enterprise-grade security, performance, and compliance.

## ğŸš€ Features

- **ğŸ¤– AI-Powered Decisions**: Local LLM integration with LM Studio and qwen2.5-7b-instruct-1m model
- **ğŸ§  Autonomous Decision Making**: AI-powered approval decisions with confidence scoring
- **ğŸ“‹ Policy Engine**: Dynamic policy interpretation and conflict resolution
- **ğŸ“Š Audit System**: Comprehensive audit trails and compliance reporting
- **ğŸ”’ Enterprise Security**: Encryption, authentication, and role-based access control
- **âš¡ High Performance**: Async/await patterns and in-memory database for fast testing
- **ğŸ³ Docker Support**: Containerized deployment with Docker and Kubernetes
- **ğŸ§ª Comprehensive Testing**: Load testing, benchmarking, and JSON report generation

## ğŸ—ï¸ Architecture

The EAI system follows a clean architecture pattern with the following layers:

- **EAI.Core**: Business logic, interfaces, and domain models
- **EAI.Api**: REST API controllers and middleware
- **EAI.Infrastructure**: Data access, external services, and LLM integrations
- **EAI.Tests**: Unit and integration tests
- **EAI.Testing**: Comprehensive load testing and benchmarking suite

## ğŸ“‹ Prerequisites

- .NET 8.0 SDK
- **LM Studio** with **qwen2.5-7b-instruct-1m** model (for AI decisions)
- In-memory database (no SQL Server required for testing)
- Docker Desktop (optional)
- Visual Studio 2022 or VS Code

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone https://github.com/your-org/eai.git
cd eai
```

### 2. Setup LM Studio

1. **Install LM Studio**: Download from [lmstudio.ai](https://lmstudio.ai)
2. **Download qwen2.5-7b-instruct-1m**: Pull the model in LM Studio
3. **Start LM Studio Server**: Run on `http://localhost:1234`

### 3. Build and Start the Application

```bash
# Build the solution
dotnet build EAI.sln

# Start the API
dotnet run --project src/EAI.Api --urls "https://localhost:58080"
```

### 4. Access the API

- **API**: https://localhost:58080
- **Health Check**: https://localhost:58080/health
- **Approval Endpoint**: https://localhost:58080/api/approval/process

## ğŸ“– Usage Examples

### Process an Approval Request

```csharp
var request = new ApprovalRequest
{
    RequestType = "expense",
    RequesterId = "user123",
    Amount = 500.00m,
    Description = "Business travel expenses",
    Department = "Sales",
    Project = "Client Meeting",
    Priority = "normal"
};

var decision = await orchestrator.ProcessApprovalRequestAsync(request);

Console.WriteLine($"Decision: {decision.Decision}");
Console.WriteLine($"Confidence: {decision.ConfidenceScore:P}");
Console.WriteLine($"Reasoning: {decision.Reasoning}");
```

### API Endpoints

#### Process Approval
```http
POST /api/approval/process
Content-Type: application/json

{
  "requestType": "expense",
  "requesterId": "user123",
  "amount": 500,
  "description": "Business travel expenses",
  "department": "Sales",
  "priority": "normal"
}
```

#### Get Audit Trail
```http
GET /api/audit/report?startDate=2024-01-01&endDate=2024-12-31
```

#### List Policies
```http
GET /api/policy
```

## ğŸ§ª Testing & Benchmarking

### Prerequisites for Testing
1. **Start the API first**:
   ```bash
   dotnet run --project src/EAI.Api --urls "https://localhost:58080"
   ```

2. **Ensure LM Studio is running** on `http://localhost:1234`

### Run Comprehensive Tests
```bash
# Run the complete testing suite
dotnet run --project src/EAI.Testing
```

### Test Output
The testing suite generates detailed JSON reports:
- **File**: `benchmark_report_YYYY-MM-DD_HH-mm-ss.json`
- **Includes**: Performance metrics, decision accuracy, LLM integration results
- **Metrics**: Response times, success rates, confidence scores, decision distribution

### Test Coverage
- âœ… **Health Check**: API availability
- âœ… **Single Request**: Individual approval processing
- âœ… **Load Testing**: 5 concurrent users, 10 requests each
- âœ… **Request Types**: Expense, Leave, Purchase approvals
- âœ… **LLM Integration**: Real AI decision making with qwen2.5-7b-instruct-1m
- âœ… **Performance Metrics**: Response times, throughput, accuracy

## ğŸ³ Docker Deployment

### Build and Run with Docker Compose
```bash
docker-compose up --build
```

### Kubernetes Deployment
```bash
kubectl apply -f k8s/deployment.yaml
```

## ğŸ“Š Monitoring & Observability

- **Structured Logging**: JSON logs with Serilog
- **Health Checks**: Database, Redis, and external service monitoring
- **Metrics**: Decision accuracy, processing latency, throughput
- **Audit Trails**: Complete decision history with encryption

## ğŸ”’ Security Features

- **Data Encryption**: AES-256 encryption for sensitive data
- **Authentication**: JWT-based authentication
- **Authorization**: Role-based access control
- **Audit Logging**: Comprehensive security event logging
- **Input Validation**: Request validation and sanitization

## ğŸ“ˆ Performance

- **Async Operations**: Non-blocking I/O operations
- **Caching**: Redis-based caching for policies and decisions
- **Connection Pooling**: Optimized database connections
- **Rate Limiting**: API rate limiting and throttling

## ğŸ”§ Configuration

### LLM Configuration (appsettings.json)
```json
{
  "LLM": {
    "Provider": "LMStudio",
    "Model": "qwen2.5-7b-instruct-1m",
    "LMStudioUrl": "http://localhost:1234",
    "MaxTokens": 1000,
    "Temperature": 0.7,
    "TopP": 0.9
  },
  "Database": {
    "UseInMemory": true,
    "SeedData": true
  }
}
```

### Environment Variables
- `LLM__LMStudioUrl`: LM Studio server URL (default: http://localhost:1234)
- `LLM__Model`: Model name (default: qwen2.5-7b-instruct-1m)
- `Database__UseInMemory`: Use in-memory database (default: true)

### Policy Configuration
Policies are defined in JSON format in the `config/policies/` directory:

```json
{
  "policyId": "expense_policy_v1",
  "policyName": "Expense Approval Policy",
  "rules": [
    {
      "condition": "amount <= 100",
      "action": "auto_approve",
      "confidenceThreshold": 0.9
    }
  ]
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author & Credits

**Enterprise Approval Intelligence (EAI)**  
Developed by: **Mateus Yonathan**

### Attribution Notice
When using this software, please include the following attribution:

```
Enterprise Approval Intelligence (EAI)
Copyright (c) 2025 Mateus Yonathan
Licensed under the Apache License, Version 2.0
```

## ğŸ†˜ Support

- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/your-org/eai/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/eai/discussions)

## ğŸ“Š Current Status

âœ… **Completed Features**:
- Local LLM integration with LM Studio/qwen2.5-7b-instruct-1m
- In-memory database with sample policies
- Comprehensive testing and benchmarking suite
- REST API with approval processing
- Policy engine with rule-based decisions
- Audit system with encrypted logging
- JSON report generation for performance analysis

ğŸ”„ **In Progress**:
- Enhanced LLM prompt engineering
- Advanced policy conflict resolution
- Performance optimization

## ğŸ—ºï¸ Roadmap

### Phase 2 Features
- Multi-modal input processing (documents, images)
- Advanced conflict resolution algorithms
- Predictive approval patterns using ML
- Dynamic policy learning and adaptation

### Phase 3 Features
- Cross-enterprise policy harmonization
- Quantum-enhanced reasoning (when available)
- Blockchain-based audit trails
- AI-powered policy generation

---

**Enterprise Approval Intelligence** - Transforming enterprise workflows with AI-powered autonomous decision making using local LLM integration.
